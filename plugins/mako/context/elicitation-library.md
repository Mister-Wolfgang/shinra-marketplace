# Elicitation Library üíÑ

50 techniques d'√©licitation organis√©es en 10 cat√©gories. Scarlet s√©lectionne 2-4 techniques par session selon ce qui bloque.

## Core (5)
1. **5 Whys** -- Demander "pourquoi ?" 5 fois pour atteindre la root cause d'un besoin flou
2. **First Principles** -- D√©composer le probl√®me en √©l√©ments fondamentaux, reconstruire depuis z√©ro
3. **Socratic Questioning** -- Questions guid√©es pour amener l'utilisateur √† clarifier sa propre pens√©e
4. **Inversion** -- "Que devrait-on faire pour que ce projet √âCHOUE ?" Inverser pour trouver les vrais besoins
5. **Critique & Refine** -- Pr√©senter une premi√®re √©bauche volontairement imparfaite, laisser l'utilisateur corriger

## Collaboration (6)
6. **Stakeholder Round Table** -- Simuler les perspectives de diff√©rents stakeholders (dev, PM, user, ops)
7. **Expert Panel** -- Simuler 3 experts du domaine avec des opinions divergentes
8. **User Persona Focus Group** -- Cr√©er 3 personas utilisateurs et tester les features depuis leur perspective
9. **Cross-Functional War Room** -- Perspectives simultan√©es : backend, frontend, infra, s√©curit√©, UX
10. **Mentor-Apprentice** -- Expliquer le projet comme √† un junior : les trous dans l'explication r√©v√®lent les trous dans les specs
11. **Improv Yes-And** -- Construire it√©rativement sur chaque id√©e de l'utilisateur ("Oui, et en plus...")

## Adversarial (5)
12. **Red Team / Blue Team** -- Attaquer les specs (trouver les failles) puis d√©fendre (renforcer)
13. **Shark Tank Pitch** -- L'utilisateur doit "pitcher" son projet en 30 secondes : force la clart√©
14. **Devil's Advocate** -- Argumenter syst√©matiquement contre chaque feature pour tester sa solidit√©
15. **Pre-mortem** -- "Le projet a √©chou√© dans 6 mois. Pourquoi ?" Identifier les risques cach√©s
16. **Good Cop / Bad Cop** -- Alterner entre validation enthousiaste et critique impitoyable

## Creative (6)
17. **SCAMPER** -- Substitute, Combine, Adapt, Modify, Put to other uses, Eliminate, Reverse
18. **Reverse Engineering** -- D√©crire le produit fini id√©al, puis remonter aux specs n√©cessaires
19. **What-If Scenarios** -- Explorer les cas limites : "Et si 10x plus d'utilisateurs ?", "Et si pas d'internet ?"
20. **Random Input Stimulus** -- Introduire un √©l√©ment al√©atoire du domaine pour d√©bloquer la r√©flexion
21. **Genre Mashup** -- "Et si c'√©tait un jeu ? Une app de dating ? Un outil m√©dical ?" Changer le contexte pour voir autrement
22. **Time Travel** -- "Comment ce projet serait con√ßu en 2030 ? En 2015 ?" Perspectives temporelles

## User-Centric (5)
23. **Day-in-Life** -- D√©rouler une journ√©e type de l'utilisateur final, identifier les touchpoints
24. **Persona Deep Dive** -- Profil d√©taill√© de l'utilisateur principal : frustrations, objectifs, comportements
25. **Customer Support Theater** -- Simuler des tickets de support : quels probl√®mes les users vont rencontrer ?
26. **Jobs-to-be-Done** -- "Quel JOB l'utilisateur 'engage' ce produit √† faire ?" Focus sur le r√©sultat, pas la feature
27. **Empathy Mapping** -- Ce que l'utilisateur pense, ressent, dit, fait par rapport au probl√®me

## Prioritization (4)
28. **MoSCoW** -- Must-have, Should-have, Could-have, Won't-have pour chaque feature
29. **Boundary Analysis** -- D√©finir pr√©cis√©ment ce qui est IN scope et OUT scope
30. **Extreme Scaling** -- "Et si on devait livrer en 1 jour ? En 1 an ?" R√©v√©ler les priorit√©s vraies
31. **Negative Requirements** -- Lister explicitement ce que le syst√®me NE DOIT PAS faire

## Risk (5)
32. **Failure Mode Analysis** -- Pour chaque composant, comment peut-il √©chouer ? Quel impact ?
33. **Chaos Monkey Scenarios** -- "Et si la DB tombe ? Et si l'API externe est down ? Et si le disque est plein ?"
34. **Threat Modeling** -- Identifier les vecteurs d'attaque : injection, escalade de privil√®ges, data leak
35. **Challenge from Critical Perspective** -- Se mettre dans la peau d'un CTO sceptique
36. **Competitor Analysis** -- "Comment font les concurrents ? Qu'est-ce qu'on fait mieux/diff√©remment ?"

## Technical (5)
37. **ADR Debate** -- Simuler un d√©bat entre 2 architectes pour chaque choix technique majeur
38. **Rubber Duck Debugging** -- Expliquer l'architecture √† voix haute, trouver les incoh√©rences
39. **Algorithm Olympics** -- Comparer 3 approches techniques avec pros/cons chiffr√©s
40. **Security Audit Personas** -- Penser comme un hacker, un auditeur, un CISO
41. **Performance Profiler Panel** -- Identifier les bottlenecks potentiels avant d'√©crire une ligne de code

## Advanced Reasoning (5)
42. **Tree of Thoughts** -- Explorer plusieurs chemins de raisonnement en parall√®le, √©valuer chaque branche
43. **Graph of Thoughts** -- Connecter les id√©es en r√©seau, identifier les d√©pendances et synergies
44. **Thread of Thought** -- D√©rouler un raisonnement lin√©aire √©tape par √©tape, v√©rifier chaque transition
45. **Self-Consistency Validation** -- R√©soudre le m√™me probl√®me 3 fois diff√©remment, v√©rifier la convergence
46. **Meta-Prompting** -- "Quelle question devrais-je te poser pour mieux comprendre ton besoin ?"

## Retrospective (4)
47. **Hindsight Reflection** -- "Sur les projets pass√©s similaires, qu'est-ce qui a surpris ?"
48. **Lessons Learned Extraction** -- Chercher en m√©moire les patterns des projets pr√©c√©dents
49. **Analogy Bridge** -- "Ce projet ressemble √† X, qu'est-ce qu'on peut en apprendre ?"
50. **Contradiction Resolution** -- Identifier les exigences contradictoires et forcer un choix

---

## Usage
Scarlet s√©lectionne 2-4 techniques par session selon le blocage rencontr√©. Elle nomme la technique dans ses questions.
Exemples :
- "Je vais utiliser **Pre-mortem** : ton projet a √©chou√© dans 6 mois. Pourquoi ?"
- "Appliquons **MoSCoW** : classe tes features en Must/Should/Could/Won't."
- "Technique **5 Whys** : pourquoi as-tu besoin de cette feature ? [x5]"
